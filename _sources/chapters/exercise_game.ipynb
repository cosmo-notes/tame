{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11809ad2-7971-4816-b92b-4905133da2a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercises part III: Game theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3feb2b",
   "metadata": {},
   "source": [
    "[Game theory](https://en.wikipedia.org/wiki/Game_theory) is a framework to consider the dynamics of games where players face each other and have to choose one strategy from a defined set of strategies. In simple two-player games, the outcome of the game can therefore be represented as a matrix $A$, where the $(i,j)$-th element represents the outcome for player 1 of choosing strategy $i$ when player 2 chooses strategy $j$. In general, we consider symmetric game where the so-called *payoff matrix* is the same for both players and a game is therefore defined by its payoff matrix $P$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a52b6-ee0d-4a9f-bd75-1eba9d65e1bd",
   "metadata": {},
   "source": [
    "## Prisoner's dilemma, nash equilibria, replicator dynamics and the Moran process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c211e14-5d1f-40a5-a2ed-4e2e2eba280f",
   "metadata": {},
   "source": [
    "The [prisoner's dilemma](https://en.wikipedia.org/wiki/Prisoner%27s_dilemma) is classic model in game theory. Two people have been caught for committing a crime together (allegedly!). The police needs evidence and offers them a deal: Snitch (or defect) on the other prisoner and you will go free. That is the best possible outcome for a prisoner, and all other outcomes will be marked with negative values to represent time in prison. If only one defects, they receive the temptation reward ($T = 0$) while the other receives the sucker reward ($S < 0$). If they both defect, they are both punished with $S<P<0$. If neither defect, they end up with a light sentence due to missing evidence, a reward $R$ in and of itself with $S<P<R<0$. \n",
    "\n",
    "Let strategy 1 be cooperation between prisoners and strategy 2 be defection, the payoff or award matrix $A$ can be represented like so:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe339ff",
   "metadata": {},
   "source": [
    "$$\n",
    "A = \n",
    "\\begin{pmatrix}\n",
    "R & S\\\\\n",
    "0 & P\n",
    "\\end{pmatrix}\n",
    "= \n",
    "\\begin{pmatrix}\n",
    "-2 & -6\\\\\n",
    "0 & -4\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c2704a-679e-4fe1-b5cd-df5409ee709d",
   "metadata": {},
   "source": [
    "What should prisoner 1 do? If they assume a 50/50 chance that the other prisoner snitches, the values given above suggest they should defect as the average of row 2 is less negative (-2) than the average of row 1 (-4). Let's call this strategy the *rational* choice. If they both act rationally, they both get four years in prison and neither of them could individually improve on this situation given additional knowledge. This fact, that no single player can improve their outcome on their own, makes the defect/defect outcome of four years in prison a [Nash Equilibrium](https://en.wikipedia.org/wiki/Nash_equilibrium).\n",
    "\n",
    "That being said, the obvious optimal outcome is for both of them to cooperate and only get two years in prison each. But that state could prove unstable because of the temptation that then exists to defect..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd51e6dc",
   "metadata": {},
   "source": [
    "The [Replicator equation](https://en.wikipedia.org/wiki/Replicator_equation) is the mean-field approach (deterministic, well-mixed, continuous) used to model such games in evolutionary dynamics. It lets us track the fitness of a given strategy as a function of the distribution of strategies in a population by letting strategies replicate or decay at a rate proportional to their fitness. In general, the replicator equation for the frequency $x_i$ of strategy $i$ in the population is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0704053a",
   "metadata": {},
   "source": [
    "$$\n",
    "\\dot{x}_i = x_i\\left[f_i(x) - \\phi(x)\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5995b7",
   "metadata": {},
   "source": [
    "where $f_i(x)$ is the fitness of strategy $i$ given the distribution of strategies and $\\phi(x)$ is the average fitness across all $n$ strategies, $\\phi(x) = \\sum_{j=1}^n x_jf_j(x)$.\n",
    "\n",
    "For the prisoner's dilemma, the fitness of a strategy would be $f_i(x) = \\sum_{k=1}^n A_{i,k}x_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c32adf",
   "metadata": {},
   "source": [
    "A [Moran process](https://en.wikipedia.org/wiki/Moran_process) is a simple stochastic model used to describe replicator dynamics in *finite* populations. It is similar to a voter model. At each time step, two random individuals are chosen: One dies and one replicates, such that the population size remains fixed. Selection can be enforced by biasing the individuals chosen for death or replication. Or, as we will attempt here, perhaps by having the individuals play out a game..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdcfbff-e88e-41f2-a071-64323d56f53b",
   "metadata": {},
   "source": [
    "1. Assuming that the winner of a Prisoner's dilemma gets to replicate over the loser, and that nothing happens during ties, construct a master equation model for a population of $N$ agents randomly playing the prisoner's dilemma.\n",
    "2. Analyze your master equation. What does the dynamic look like? Do the outcomes match what is expected from the deterministic replicator equation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adf5fd8",
   "metadata": {},
   "source": [
    "## Rock-paper-scissors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b9bce2",
   "metadata": {},
   "source": [
    "[Rock-paper-scissors](https://en.wikipedia.org/wiki/Rock_paper_scissors) is a simple two-player game that lets us explore an example where three strategies are available for each player. The payoff matrix has three possible outcomes: win (1), tie (0), and loss (-1). We can therefore write the game as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749e76e3",
   "metadata": {},
   "source": [
    "$$\n",
    "A = \n",
    "\\begin{pmatrix}\n",
    "0 & -1 & 1\\\\\n",
    "1 & 0 & -1\\\\\n",
    "-1 & 1 & 0\\\\\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c600e52",
   "metadata": {},
   "source": [
    "1. First, construct a master equation model for the Moran process of the rock-paper-scissors game.\n",
    "2. Second, write the replicator equations for the rock-paper-scissors game.\n",
    "3. Do the two approaches predict the same kind of behavior?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
